namespace pelican {

/**
\page user_referencePipelines Pipelines

\section user_referencePipelines_introduction Introduction

Pelican pipelines act as containers for the data processing framework.
A pipeline is simply a C++ class that defines the operations performed
on a single chunk of stream data, and is run repeatedly by the
pipeline driver whenever there is a new chunk of data available to be
processed. The data processing itself actually happens within pipeline
modules.

There are no default pipelines: in order to process data using Pelican,
you will need to write your own pipeline class.
Fortunately, this is very simple.

\section user_referencePipelines_overview Overview

To create a new pipeline:

\li Inherit from the \c AbstractPipeline class, which defines the pipeline
    interface.
\li In the derived class, implement the \c init() method to perform one-off
    initialisation, such as creating pipeline modules, and to request the
    remote data required to run the pipeline.
\li In the derived class, implement the \c run() method to define the
    operations carried out for each iteration of the pipeline.
\li There are some protected methods in \c AbstractPipeline (detailed below)
    that should be used when setting up the pipeline.

\subsection user_referencePipelines_overview_init The init() method

Here you must specify the types of data required using the
\c requestRemoteData() protected method. It takes at least one argument, which 
is a string containing the type-name (the class name) of the required data blob.
The method should be called as many times as required to fulfil all remote
data requirements. An optional second argument allows you to specify the number
of DataBlobs of this type to store in a history buffer. Using a history
buffer allows your pipeline to refer to previous DataBlobs 
( via the \streamHistory() method) without incuring the performance 
penalty of an unnessasary data copy.

One-off initialisation, such as creating pipeline modules, should also be
performed here. Use the \c createModule() protected method with the module
type (class name) and an optional given name (if using a configuration file
containing multiple different configurations for the same module type).
The method returns an \c AbstractModule pointer, which should be stored and
used to call methods on the module.

If there are any data blobs that exist local to the pipeline (i.e. that are
not provided as part of the remote data), then they should also be created
here using the \c createBlob() protected method. The method returns a
\c DataBlob base class pointer.

\subsection user_referencePipelines_overview_run The run() method

This is where data processing happens, and is called each time a new
data chunk is available. The method is supplied with a hash of data blob
pointers to the remote data requested in the \c init() method: this hash
of pointers is updated each time the method is called. The hash keys are
of type \c QString, and correspond to the class names of the data blobs.
To get the data blob pointers, look them up in the hash using their names with
the \c [] dereference operator (see example, below).

The data blob pointers are then passed to the pipeline modules as required.
Since the pipeline is just a C++ class, it can be used just like any other:
private state variables can be used if required, and the pipeline can call
methods on any objects known to it. The pipeline modules simply provide a
convenient way to encapsulate functionality.

<b>However, it is important to remember that the \c run() method should only
be used to define a single iteration of the pipeline.</b> The method must exit
before the next chunk of data can be processed.

Pipelines must be registered with the pipeline driver in \c main(): see the
section on \link user_referenceMain writing main()\endlink for more details.

\section user_referencePipelines_example Example

In the following, a new pipeline is created to generate an image from
remote visibility data. The \c init() method creates the pipeline modules
using the \c createModule() protected method, creates the local image data
blob using \c createBlob(), and requests remote data to be supplied to the
pipeline using the \c requestRemoteData() method.

This example creates a new image each time the \c run() method is called.
The modules are configured using their own settings from the XML configuration
file.

The class definition is:

\include PipelineExample.h

and the class implementation is:

\include PipelineExample.cpp

\latexonly
\clearpage
\endlatexonly

*/

}
